{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK0u8NVn4R4R9AUECysV8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/savindu29/NeuralNet/blob/main/2dcnnlstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hznLdGsUD0AC",
        "outputId": "cf6af493-e294-45a7-ca81-b00723c90c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mne\n",
        "!cp /content/drive/MyDrive/nuralnet/BCICIV_2a_gdf.zip /content\n",
        "!unzip /content//BCICIV_2a_gdf.zip -d data"
      ],
      "metadata": {
        "id": "c6QT38SvEoIX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "from mne.preprocessing import ICA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "RKt42axUEUWF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EEGPreprocessor:\n",
        "    def __init__(self, l_freq=8.0, h_freq=30.0, notch_freq=50, tmin=0, tmax=2, overlap=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the EEG Preprocessor with adjustable parameters.\n",
        "        :param l_freq: Lower bound of the bandpass filter (Hz).\n",
        "        :param h_freq: Upper bound of the bandpass filter (Hz).\n",
        "        :param notch_freq: Frequency to apply the notch filter (e.g., 50 or 60 Hz).\n",
        "        :param tmin: Start time for epoching (seconds).\n",
        "        :param tmax: End time for epoching (seconds).\n",
        "        :param overlap: Overlap ratio for epoching (0.0 to 1.0).\n",
        "        \"\"\"\n",
        "        self.l_freq = l_freq\n",
        "        self.h_freq = h_freq\n",
        "        self.notch_freq = notch_freq\n",
        "        self.tmin = tmin\n",
        "        self.tmax = tmax\n",
        "        self.overlap = overlap\n",
        "\n",
        "    def read_data(self, path):\n",
        "        \"\"\"\n",
        "        Load and preprocess EEG data from a GDF file, including filtering, applying ICA,\n",
        "        epoching, and extracting spectral features.\n",
        "        \"\"\"\n",
        "        # Load raw EEG data from GDF file\n",
        "        raw = mne.io.read_raw_gdf(path, preload=True)\n",
        "\n",
        "        # Apply bandpass filter to remove frequencies outside the EEG range\n",
        "        raw = raw.filter(l_freq=self.l_freq, h_freq=self.h_freq)\n",
        "\n",
        "        # Apply notch filter to remove power line noise (50Hz or 60Hz depending on region)\n",
        "        raw.notch_filter(freqs=self.notch_freq)\n",
        "\n",
        "        # Apply ICA for artifact rejection (eye blinks, muscle artifacts, etc.)\n",
        "        ica = ICA(n_components=20, random_state=97, max_iter=800)\n",
        "        ica.fit(raw)\n",
        "\n",
        "        # Dynamically detect and handle EOG channels if present\n",
        "        try:\n",
        "            eog_indices, scores = ica.find_bads_eog(raw)\n",
        "            print(f\"EOG component indices identified: {eog_indices}\")\n",
        "            ica.exclude = eog_indices\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Warning: No EOG channels found. Skipping EOG artifact removal. Error: {e}\")\n",
        "\n",
        "        # Apply ICA to remove the artifacts (based on the ICA components)\n",
        "        raw_cleaned = ica.apply(raw)\n",
        "\n",
        "        # Set the EEG reference (common average reference)\n",
        "        raw_cleaned.set_eeg_reference()\n",
        "\n",
        "        # Extract events and annotations\n",
        "        events, _ = mne.events_from_annotations(raw_cleaned)\n",
        "\n",
        "        # Print out available event IDs for debugging\n",
        "        print(f\"Available events for {path}: {set(events[:, -1])}\")\n",
        "\n",
        "        # Dynamically set valid event IDs based on the available events in the data\n",
        "        available_event_ids = set(events[:, -1])\n",
        "        valid_event_ids = list(available_event_ids)\n",
        "\n",
        "        if not valid_event_ids:\n",
        "            raise ValueError(f\"No valid event IDs found in the data for {path}. Available event IDs: {available_event_ids}\")\n",
        "\n",
        "        # Create epochs with overlap based on valid event IDs\n",
        "        epochs = mne.make_fixed_length_epochs(\n",
        "            raw_cleaned, duration=(self.tmax - self.tmin), overlap=self.overlap, preload=True\n",
        "        )\n",
        "\n",
        "        # Get labels and features\n",
        "        labels = epochs.events[:, -1]  # Last column contains labels\n",
        "        features = epochs.get_data()   # EEG data from the epochs\n",
        "\n",
        "        return features, labels\n",
        "\n",
        "    def process_multiple_files(self, directory_path):\n",
        "        \"\"\"\n",
        "        Process only motor imagery (task) .gdf files in the given directory.\n",
        "        Filters out resting (eyes-closed) files and processes only task files.\n",
        "        \"\"\"\n",
        "        features = []\n",
        "        labels = []\n",
        "        groups = []\n",
        "\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.endswith('.gdf') and 'T' in filename:  # Only motor imagery files\n",
        "                file_path = os.path.join(directory_path, filename)\n",
        "                print(f\"Processing file: {file_path}\")\n",
        "                feature, label = self.read_data(file_path)\n",
        "                features.append(feature)\n",
        "                labels.append(label)\n",
        "                subject_group = filename[:3]  # Extract subject group (e.g., 'A01')\n",
        "                groups.append([subject_group] * len(label))\n",
        "\n",
        "        features = np.concatenate(features, axis=0)\n",
        "        labels = np.concatenate(labels, axis=0)\n",
        "        groups = np.concatenate(groups, axis=0)\n",
        "\n",
        "        # Normalize the features (standardization)\n",
        "        features = self.standardize_data(features)\n",
        "\n",
        "        # Encode labels to integers\n",
        "        label_encoder = LabelEncoder()\n",
        "        labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "        # Convert labels to one-hot encoding for multi-class classification\n",
        "        labels = to_categorical(labels)\n",
        "\n",
        "        # Reshape features for CNN-LSTM hybrid input\n",
        "        features = features.reshape(features.shape[0], features.shape[1], features.shape[2], 1)\n",
        "\n",
        "        return features, labels, groups\n",
        "\n",
        "    def standardize_data(self, data):\n",
        "        \"\"\"\n",
        "        Standardize the EEG data: mean=0, std=1 across each feature (channel).\n",
        "        This helps normalize the signal amplitude and speed up training convergence.\n",
        "        \"\"\"\n",
        "        num_samples, num_channels, num_time_points = data.shape\n",
        "        standardized_data = np.zeros_like(data)\n",
        "\n",
        "        # Apply standardization across each channel\n",
        "        for i in range(num_channels):\n",
        "            for j in range(num_samples):\n",
        "                standardized_data[j, i, :] = (data[j, i, :] - np.mean(data[j, i, :])) / np.std(data[j, i, :])\n",
        "\n",
        "        return standardized_data\n",
        "\n",
        "    def extract_psd_features(self, raw_data):\n",
        "        \"\"\"\n",
        "        Extract Power Spectral Density (PSD) features from the raw EEG data.\n",
        "        This provides a frequency-domain representation of the EEG signal.\n",
        "        \"\"\"\n",
        "        psd, freqs = mne.time_frequency.psd_welch(raw_data, fmin=self.l_freq, fmax=self.h_freq)\n",
        "        return psd\n",
        "\n",
        "    def extract_connectivity_features(self, raw_data):\n",
        "        \"\"\"\n",
        "        Extract functional connectivity features such as coherence or correlation between EEG channels.\n",
        "        This measures how synchronously different channels are working together.\n",
        "        \"\"\"\n",
        "        # For simplicity, let's extract coherence between pairs of channels (you can extend to other measures)\n",
        "        connectivity_matrix = mne.connectivity.envelope_correlation(raw_data.get_data())\n",
        "        return connectivity_matrix\n"
      ],
      "metadata": {
        "id": "SbKJvfx7Eiue"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "data_directory = '/content/data'  # Path to the directory containing .gdf files\n",
        "preprocessor = EEGPreprocessor()\n",
        "\n",
        "# Process all .gdf files in a directory\n",
        "features, labels, groups = preprocessor.process_multiple_files(data_directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "oY_7n72jE1BE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save processed data\n",
        "save_path = '/content/eeg_preprocessed_data'  # Local path in Colab\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the processed data to disk\n",
        "np.savez_compressed(f\"{save_path}/eeg_data.npz\", features=features, labels=labels, groups=groups)\n",
        "print(\"Preprocessed data saved to disk.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXulWhX7eJ8G",
        "outputId": "1bdb4e8c-285f-495e-a375-2ed58340a26d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed data saved to disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the saved data in future sessions, use the following:\n",
        "loaded_data = np.load(f\"{save_path}/eeg_data.npz\")\n",
        "features = loaded_data['features']\n",
        "labels = loaded_data['labels']\n",
        "groups = loaded_data['groups']\n",
        "\n",
        "# Print shapes to verify data loading\n",
        "print(f\"Features shape: {features.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Groups shape: {groups.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnWPz2MrMa8S",
        "outputId": "0dac488f-a957-4d69-99fd-4802067606b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (16010, 25, 500, 1)\n",
            "Labels shape: (16010, 1)\n",
            "Groups shape: (16010,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Reshape, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # 2D Convolutional Layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))  # Reduce overfitting\n",
        "\n",
        "    # Additional Convolutional Layer\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Additional Convolutional Layer for deeper feature extraction\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Flatten the output and prepare for LSTM\n",
        "    model.add(Flatten())\n",
        "    model.add(Reshape((-1, 128)))  # Reshape for LSTM (batch_size, time_steps, features)\n",
        "\n",
        "    # LSTM Layer\n",
        "    model.add(LSTM(128, return_sequences=False, activation='tanh'))\n",
        "    model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
        "\n",
        "    # Fully connected output layer for multi-class classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model with categorical cross-entropy loss for multi-class classification\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0YSOj1i0M-pT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming features and labels are already loaded as NumPy arrays\n",
        "\n",
        "# Set input shape for the model\n",
        "input_shape = features.shape[1:]  # (time_steps, channels, 1)\n",
        "num_classes = labels.shape[1]     # Number of classes\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the model\n",
        "model = create_cnn_lstm_model(input_shape, num_classes)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDfU1STMNBxD",
        "outputId": "6fc777cd-2fbf-4270-9927-544fef690ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 63/201\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:09\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0000e+00"
          ]
        }
      ]
    }
  ]
}